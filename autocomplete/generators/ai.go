package generators

import (
	"bytes"
	"encoding/json"
	"io"
	"log/slog"
	"math"
	"net/http"
	"os"
	"os/exec"
	"strings"

	"github.com/cpendery/clac/autocomplete/model"
	"github.com/google/uuid"
)

const (
	apiKeyEnvVar      = "CLAC_AI_TOKEN"
	apiEndpoint       = "https://api.openai.com/v1/chat/completions"
	maxTokens         = 4097
	tokensToRuneRatio = 4
	marginRatio       = 0.8
	maxRunes          = maxTokens * tokensToRuneRatio * marginRatio
)

type PromptFunction func(executeShellCommand func(string) string) string
type MessageFunction func(executeShellCommand func(string) string) string

type apiResponse struct {
	Choices []choice `json:"choices"`
}
type choice struct {
	Message message        `json:"message"`
	Info    map[string]int `json:"info"`
}
type message struct {
	Content *string `json:"content,omitempty"`
}

type apiRequest struct {
	Model    string       `json:"model"`
	Messages []apiMessage `json:"messages"`
}

type apiMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

func enabled() bool {
	return len(os.Getenv(apiKeyEnvVar)) != 0
}

func executeShellCommand(script string) string {
	args := strings.Split(script, " ")
	var cmd *exec.Cmd = nil
	if len(args) > 1 {
		cmd = exec.Command(args[0], args[1:]...)
	} else {
		cmd = exec.Command(args[0])
	}
	output, err := cmd.Output()
	if err != nil {
		slog.Error("failed to run script in generator", slog.String("script", script), slog.String("error", err.Error()), slog.String("output", string(output)))
		return ""
	}
	return string(output)
}

func request(name, prompt, message, splitOn string) []model.TermSuggestion {
	suggestions := []model.TermSuggestion{}
	jsonBytes, err := json.Marshal(apiRequest{
		Model: "gpt-3.5-turbo",
		Messages: []apiMessage{
			{Role: "system", Content: prompt},
			{Role: "user", Content: message},
		},
	})
	if err != nil {
		slog.Error("unable to marshal ai request", slog.String("error", err.Error()))
		return suggestions
	}

	apiKey := os.Getenv(apiKeyEnvVar)
	request, _ := http.NewRequest("POST", apiEndpoint, bytes.NewBuffer(jsonBytes))
	request.Header.Set("Content-Type", "application/json")
	request.Header.Set("Authorization", "Bearer "+apiKey)
	client := http.Client{}
	response, err := client.Do(request)
	if err != nil {
		slog.Error("failed to make ai request", slog.String("error", err.Error()))
		return suggestions
	}
	if response.StatusCode != 200 {
		contentBytes, _ := io.ReadAll(response.Body)
		slog.Error("failed to make ai request", slog.String("status", response.Status), slog.String("content", string(contentBytes)))
		return suggestions
	}

	responseBody, err := io.ReadAll(response.Body)
	if err != nil {
		slog.Error("failed to read ai response", slog.String("error", err.Error()))
		return suggestions
	}

	var responseData apiResponse
	if err := json.Unmarshal(responseBody, &responseData); err != nil {
		slog.Error("invalid json response", slog.String("error", err.Error()))
		return suggestions
	}

	aiSuggestions := []string{}
	for _, choice := range responseData.Choices {
		content := choice.Message.Content
		if content == nil {
			continue
		}
		if splitOn != "" {
			for _, s := range strings.Split(*content, splitOn) {
				if strings.TrimSpace(s) != "" {
					aiSuggestions = append(aiSuggestions, s)
				}
			}

		} else {
			aiSuggestions = append(aiSuggestions, *content)
		}
	}
	for _, aiSuggestion := range aiSuggestions {
		suggestions = append(suggestions, model.TermSuggestion{
			Name:        `"` + aiSuggestion + `"`,
			Description: "Generated by Clac AI\n\n" + aiSuggestion,
			Type:        model.TermSuggestionTypeAI,
		})
	}
	return suggestions
}

func AI(name string, prompt PromptFunction, message MessageFunction, splitOn string) *model.Generator {
	return &model.Generator{
		Id: uuid.New(),
		Function: func() []model.TermSuggestion {
			suggestions := []model.TermSuggestion{}
			if !enabled() {
				return suggestions
			}

			promptContent := prompt(executeShellCommand)
			messageContent := ""
			if message != nil {
				messageContent = message(executeShellCommand)
			}

			budget := int(math.Floor(maxRunes)) - len(promptContent)
			if len(messageContent) > budget {
				messageContent = messageContent[:budget]
			}

			return request(name, promptContent, messageContent, splitOn)
		},
	}
}
